{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL RBFNN - A&D",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beny2000/HeartDiseaseClassifier/blob/main/FINAL_RBFNN_A%26D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9WCVweekAti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374c12fe-b7d7-45a3-95bf-ea4d6bd4da04"
      },
      "source": [
        "#connect to anvil \n",
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "anvil.server.connect(\"2ZZFEIO7RSWJ2NSXVOIJU7NK-PUMVCYIB7OL5ZPSL\")\n",
        "\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from importlib import reload\n",
        "reload(sns)\n",
        "\n",
        "#load data set \n",
        "cleveland = pd.read_csv('heart.csv')\n",
        "data = cleveland\n",
        "data.columns = ['Age','Sex','CP', 'BP','Cholesterol','BS', 'RestECG_Results','MaxHR', 'exind_Angina', 'ST_Depression','ST_Slope','MajorVessels','Thal_Test',\"HD\"]\n",
        "\n",
        "#separating into x and y data sets\n",
        "preX = np.array(data.drop(['HD'], 1)) #all other data \n",
        "y = np.array(data['HD']) \n",
        "\n",
        "#preprocess data\n",
        "X = preprocessing.normalize(preX)\n",
        "\n",
        "#create test and train datasets \n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
        "stratify=y, random_state=0, test_size = 0.2)\n",
        "\n",
        "\n",
        "#pythagorean calculation\n",
        "def get_distance(x1, x2):\n",
        "    sum = 0\n",
        "    for i in range(len(x1)):\n",
        "        sum += (x1[i] - x2[i]) ** 2\n",
        "    return np.sqrt(sum)\n",
        "\n",
        "#modified kmeans, returns the cluster centroids and the standard deviations \n",
        "def kmeans(X, k, max_iters): \n",
        "    np.random.seed(43)\n",
        "\n",
        "    centroids = X[np.random.choice(range(len(X)), k, replace=False)] #centroids \n",
        "    converged = False\n",
        "    \n",
        "    current_iter = 0\n",
        "\n",
        "    while (not converged) and (current_iter < max_iters):\n",
        "\n",
        "        cluster_list = [[] for i in range(len(centroids))]\n",
        "\n",
        "        for x in X:  # Go through each data point\n",
        "            distances_list = []\n",
        "            for c in centroids:\n",
        "                distances_list.append(get_distance(c, x))\n",
        "            cluster_list[int(np.argmin(distances_list))].append(x) ##list of min distances to centroids\n",
        "\n",
        "        cluster_list = list((filter(None, cluster_list)))\n",
        "\n",
        "        prev_centroids = centroids.copy()\n",
        "\n",
        "        centroids = []\n",
        "\n",
        "        for j in range(len(cluster_list)):\n",
        "            centroids.append(np.mean(cluster_list[j], axis=0))\n",
        "\n",
        "        pattern = np.abs(np.sum(prev_centroids) - np.sum(centroids))\n",
        "\n",
        "        converged = (pattern == 0)\n",
        "\n",
        "        current_iter += 1\n",
        "\n",
        "    return np.array(centroids), [np.std(x) for x in cluster_list]\n",
        "\n",
        "\n",
        "##RBF class\n",
        "class RBF:\n",
        "\n",
        "    def __init__(self, U, X, y, tX, ty, num_of_classes,\n",
        "                 k, std_from_clusters):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.tX = tX\n",
        "        self.ty = ty\n",
        "\n",
        "        self.number_of_classes = num_of_classes\n",
        "        self.k = k\n",
        "        self.std_from_clusters = std_from_clusters\n",
        "        self.U = U\n",
        "        \n",
        "    #converting array to a one-hot encoded 2D matrix (i.e. 2 = 0 0 1 0)\n",
        "    def convert_to_one_hot(self, x, num_of_classes): \n",
        "        arr = np.zeros((len(x), num_of_classes)) \n",
        "        for i in range(len(x)): \n",
        "            c = int(x[i]) \n",
        "            arr[i][c] = 1 \n",
        "        return arr\n",
        "\n",
        "    #calculating exponential function ## using beta = 1/std^2 \n",
        "    def rbf(self, x, c, s):\n",
        "        distance = get_distance(x, c)\n",
        "        return np.exp((-1/(2*(s**2)))*(distance**2))\n",
        "\n",
        "    # creates list of the betas\n",
        "    def rbf_list(self, X, centroids, std_list):\n",
        "        RBF_list = []\n",
        "        for x in X:\n",
        "            RBF_list.append([self.rbf(x, c, s) for (c, s) in zip(centroids, std_list)])\n",
        "        return np.array(RBF_list)\n",
        "\n",
        "    def fit(self):\n",
        "\n",
        "        #finding the centroids and the standard deviiation of datapoints to centroids\n",
        "        self.centroids, self.std_list = kmeans(self.X, self.k, max_iters=100000)\n",
        "        self.cent = self.centroids\n",
        "\n",
        "        #enter if std_from_clusters is false (other method for finding beta, this was determined to be less accurate that 1/std^2 method)\n",
        "        if not self.std_from_clusters: ##Calculate betas using beta = sqrt(2*k)/dmax \n",
        "            dMax = np.max([get_distance(c1, c2) for c1 in self.centroids for c2 in self.centroids]) #dmax = max distance between centroids\n",
        "            self.std_list = np.repeat(np.sqrt(2 * self.k)/dMax, self.k)\n",
        "            \n",
        "\n",
        "        RBF_X = self.rbf_list(self.X, self.centroids, self.std_list)\n",
        "\n",
        "        #optimizing for weights using least squares regression \n",
        "        self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.convert_to_one_hot(self.y, self.number_of_classes)\n",
        "       \n",
        "        #test and calculate for accuracy \n",
        "        RBF_list_tst = self.rbf_list(self.tX, self.centroids, self.std_list)\n",
        "        self.pred_ty = RBF_list_tst @ self.w\n",
        "        self.pred_ty = np.array([np.argmax(x) for x in self.pred_ty])\n",
        "        diff = self.pred_ty - self.ty\n",
        "        Accuracy = len(np.where(diff == 0)[0]) / len(diff)\n",
        "       \n",
        "        #run user data\n",
        "        RBF_U = self.rbf_list(self.U, self.centroids, self.std_list)\n",
        "        self.pred_y = RBF_U @ self.w\n",
        "        return self.pred_y, Accuracy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.6/dist-packages (0.3.34)\n",
            "Requirement already satisfied: ws4py in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: argparse in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (1.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment (dev)\" as SERVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA9X-46nuN1a"
      },
      "source": [
        "##callable function \r\n",
        "@anvil.server.callable\r\n",
        "def get_prediction(Age, Sex, CP, BP, Cholesterol, BS,RestECG_Results,MaxHR,exind_Angina,ST_Depression,ST_Slope,MajorVessels,Thal_Test):\r\n",
        "  preUser = [Age, Sex, CP, BP, Cholesterol, BS,RestECG_Results,MaxHR,exind_Angina,ST_Depression,ST_Slope,MajorVessels,Thal_Test]\r\n",
        "  #normalize user data \r\n",
        "  User = preprocessing.normalize([preUser])\r\n",
        "  #run RBF model \r\n",
        "  RBF_CLASSIFIER = RBF(User,X_train, y_train, X_test, y_test, num_of_classes=max(y_train)+1,\r\n",
        "                      k=28, std_from_clusters=True)\r\n",
        "  Output = RBF_CLASSIFIER.fit()\r\n",
        "  print(Output)\r\n",
        "  Acc = round(Output[1]*100,2)\r\n",
        "  Heart = max(Output[0])\r\n",
        "  yn = np.argmax(Heart)\r\n",
        "  HD = round(max(Heart)*100,2)\r\n",
        "  return yn, Acc\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-3YWwsR5TD_",
        "outputId": "7e2ed0dd-90e8-4eb4-c31e-063e817c3127"
      },
      "source": [
        "anvil.server.wait_forever()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[0.70738059, 0.2978751 ]]), 0.8852459016393442)\n",
            "(array([[0.07287669, 0.92504605]]), 0.8852459016393442)\n",
            "(array([[0.14246154, 0.85509569]]), 0.8852459016393442)\n",
            "(array([[ 1.21303506, -0.21274632]]), 0.8852459016393442)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXr7YvVxlri5"
      },
      "source": [
        "Overall Findings:\r\n",
        "\r\n",
        "For severity levels - best beta is option 2, with a k of 71 \r\n",
        "\r\n",
        "For binary heart disease - best beta is option 1, with a k of 37\r\n",
        "![image.png]()\r\n"
      ]
    }
  ]
}